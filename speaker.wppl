var speechCost = 0
var pointCost = 70
var successValue = 100

var invLogit = function(x) {
  return Math.exp(x) / (1+Math.exp(x))
}

var knowProb = function(exposure) {
  return invLogit(-.4252 + 1.1487*Math.log2(exposure))
}


var exposure = 1

var actions = ['speak', 'point'];

var outcome = function(action, exposure) {
  var outcomes = ['point_success', 'speak_success', 'failure'];
  var successProbs = (action === 'speak') ? 
      [0, knowProb(exposure), 1 - knowProb(exposure)] : [1, 0, 0]
  return categorical(successProbs, outcomes);
};

var utility = function(outcome) {
  var table = { 
    point_success: successValue - pointCost, 
    speak_success: successValue - speechCost,
    failure: 0,
  };
  return table[outcome];
};

var sampleSpeaker = function() {
  return Infer({ 
    model() {

      var action = uniformDraw(actions);
      
      var expectedUtility = function(action) {
        return expectation(Infer({ 
          model() {
            return utility(outcome(action, exposure));
          }
        }));
      };
      
      factor(Math.log(expectedUtility(action)));
      
      return action;
    }
  });
};




var learning = function(known, prob) {
  // model that takes 0/1 knowledge and updates based on trials, based on some parameter P
  var probLearned = flip(prob)
  // no forgetting, so only update prob if unknown
  if(known==true) {return true;} else {return probLearned;}
  //return known
}

var trials= ['wug','toma','toma','dax','dax','dax','dax',
             'fep','blicket','blicket','kreeb','kreeb','kreeb','kreeb',
             'gazzer','kiv','kiv','manu','manu','manu','manu',]


var initializeVocab = function(emptyArray) {
  var wordList = ["blicket", "kreeb", "wug", "fep", 
                          "toma", "dax", "gazzer", "kiv","manu"]
  map(function(element) {
     var newWord = {
       label: element,
       exposures: 0,
       known: 0
     };
     emptyArray.push(newWord)
  }, wordList)
  return emptyArray
}


var training = function(trialArray, vocabulary, learnProb) {

  var vocabSlice = vocabulary.splice()

  if (vocabSlice.length == 0) {
    initializeVocab(vocabSlice)
  }

  map(function(currentOne) {
    var vocabIndex = map(function(e) {return e.label;}, vocabSlice).indexOf(currentOne)
      var wordToUpdate = vocabSlice[vocabIndex] 

      var updatedWord =  { 
        label: wordToUpdate.label,
        exposures: wordToUpdate.exposures+1, 
        known: learning(wordToUpdate.known, learnProb) 
      }

      vocabSlice.splice(vocabIndex, 1, updatedWord)  
  }, trialArray)

  return vocabSlice 
}



var sameVocabulary = function(myVocab, yourVocab) {
  var differences = []
  map2(function(x, y) {
    // return x.known != y.known
    if (x.known != y.known) {
      differences.push('notSame')
    } 
  }, 
  myVocab,
  yourVocab)    
  return differences.length==0
}

var estimateLearnProb = function(vocabulary) {
  var parameter = sample(Beta({a:.5,b:.5}));

  var learnSample = training(trials, [], parameter);

  condition(sameVocabulary(vocabulary, learnSample))
  //condition(parameter < .4)
  return parameter;
  //return learnSample;
}

// use training() to infer what distribution over Ps (see factor() and logistic regression examples)
var simulate = function(trialArray) {
  // rough
  // return expectation(Infer({ 
  //  model() {
  //    return training(trialArray));
  //  }
  //}));    
}


  // var vocabEx1= [{"label":"wug","exposures":1,"known":false}, {"blicket":"wug","exposures":1,"known":false}]
  // var vocabEx2= [{"label":"wug","exposures":3,"known":false}, {"blicket":"wug","exposures":1,"known":false}]
  // sameVocabulary(vocabEx1,vocabEx2)
  

// repeat(10, function() {training(trials,[], .3)})
var myLearning = training(trials,[], .45)

// myLearning
// estimateLearnProb(myLearning)

Infer({method: 'rejection', samples: 5000}, function() {estimateLearnProb(myLearning)})


//training(trials, [])
//repeat(3, function() {training(trials, [], .45)})
//repeat(1, function() {learning(0, 1)})

//(repeat(100, function() { sample(sampleSpeaker())}))
//repeat(10,speakerProduces)