var speechCost = 0
var pointCost = 70
var successValue = 100

var invLogit = function(x) {
  return Math.exp(x) / (1+Math.exp(x))
}

var knowProb = function(exposure) {
  return invLogit(-.4252 + 1.1487*Math.log2(exposure))
}


var exposure = 1

var actions = ['speak', 'point'];

var outcome = function(action, exposure) {
  var outcomes = ['point_success', 'speak_success', 'failure'];
  var successProbs = (action === 'speak') ? 
      [0, knowProb(exposure), 1 - knowProb(exposure)] : [1, 0, 0]
  return categorical(successProbs, outcomes);
};

var utility = function(outcome) {
  var table = { 
    point_success: successValue - pointCost, 
    speak_success: successValue - speechCost,
    failure: 0,
  };
  return table[outcome];
};

var sampleSpeaker = function() {
  return Infer({ 
    model() {

      var action = uniformDraw(actions);
      
      var expectedUtility = function(action) {
        return expectation(Infer({ 
          model() {
            return utility(outcome(action, exposure));
          }
        }));
      };
      
      factor(Math.log(expectedUtility(action)));
      
      return action;
    }
  });
};

var learning = function(known) {
  // model that takes 0/1 knowledge and updates based on trials, based on some parameter P
  var probLearned = flip(.5)
  // no forgetting, so only update prob if unknown
  if(known==true) {return true;} else {return probLearned;}
}

var trials= ['wug','toma','toma','dax','dax','dax','dax']




var training = function(trialArray, vocabulary) {
  // if (trialArray.length == 0) {return vocabulary}

  // calls learning on a training set...
  // var currentOne = trialArray.pop()

  map(function(currentOne) {
    var repeatIndex = map(function(e) {return e.label;}, vocabulary).indexOf(currentOne)
    if(repeatIndex > -1) {
      var wordToUpdate = vocabulary[repeatIndex] 

      var updatedWord = extend(wordToUpdate, { 
        exposures: wordToUpdate.exposures+1, 
        known: learning(wordToUpdate.known) 
      })

      vocabulary.splice(repeatIndex, 1, updatedWord) 

    } else {

      var newWord = {
       label: currentOne,
       exposures: 1,
       known: learning(0)
      };
      vocabulary.push(newWord)

    }
  }, trialArray)

  return vocabulary

  // if we are done, return
  // if (trialArray.length >= 0) {training(trialArray, vocabulary)}
}


// use training() to infer what distribution over Ps (see factor() and logistic regression examples)
var simulate = function(trialArray) {
  // rough
  // return expectation(Infer({ 
  //  model() {
  //    return training(trialArray));
  //  }
  //}));    
}


//training(trials, [])
repeat(3, function() {training(trials, [])})
//repeat(1, function() {learning(0, 1)})

//(repeat(100, function() { sample(sampleSpeaker())}))
//repeat(10,speakerProduces)